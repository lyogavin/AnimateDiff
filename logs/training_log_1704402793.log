training config: {'image_finetune': False, 'output_dir': 'output_1704402793', 'pretrained_model_path': 'models/StableDiffusion', 'unet_additional_kwargs': {'use_inflated_groupnorm': True, 'unet_use_cross_frame_attention': False, 'unet_use_temporal_attention': False, 'use_motion_module': True, 'motion_module_resolutions': [1, 2, 4, 8], 'motion_module_mid_block': True, 'motion_module_decoder_only': False, 'motion_module_type': 'Vanilla', 'motion_module_kwargs': {'num_attention_heads': 8, 'num_transformer_block': 1, 'attention_block_types': ['Temporal_Self', 'Temporal_Self'], 'temporal_position_encoding': True, 'temporal_position_encoding_max_len': 32, 'temporal_attention_dim_div': 1}}, 'noise_scheduler_kwargs': {'num_train_timesteps': 1000, 'beta_start': 0.00085, 'beta_end': 0.012, 'beta_schedule': 'linear', 'steps_offset': 1, 'clip_sample': False}, 'train_data': {'csv_path': 'data/animated_diff_ds_1704397657.csv', 'video_folder': 'data/', 'sample_size': 256, 'sample_stride': 4, 'sample_n_frames': 16}, 'validation_data': {'prompts': ['A sprite sheet animation of green color bullet effect from bottom of the screen to the top.', 'A sprite sheet animation of a fire with smokes around it.'], 'num_inference_steps': 25, 'guidance_scale': 8.0}, 'trainable_modules': ['motion_modules.'], 'unet_checkpoint_path': 'models/Motion_Module/mm_sd_v15_v2.ckpt', 'learning_rate': 0.0001, 'train_batch_size': 4, 'max_train_epoch': -1, 'max_train_steps': 1000, 'checkpointing_epochs': -1, 'checkpointing_steps': 200, 'validation_steps': 100, 'validation_steps_tuple': [2, 50], 'global_seed': 42, 'mixed_precision_training': True, 'enable_xformers_memory_efficient_attention': True, 'is_debug': False}
using output_dir: output_1704402793/sprite_sheet_training-2024-01-04T21-13-23
using max tokens: 77
loaded 3D unet's pretrained weights from models/StableDiffusion/unet ...
### missing keys: 588; 
### unexpected keys: 0;
### Motion Module Parameters: 453.20928 M
unet_checkpoint_path: models/Motion_Module/mm_sd_v15_v2.ckpt
### from checkpoint: models/Motion_Module/mm_sd_v15_v2.ckpt
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: mid_block.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
### missing keys: 686, unexpected keys: 0, total keys: 588
### missing keys: ['conv_in.weight', 'conv_in.bias', 'time_embedding.linear_1.weight', 'time_embedding.linear_1.bias', 'time_embedding.linear_2.weight', 'time_embedding.linear_2.bias', 'down_blocks.0.attentions.0.norm.weight', 'down_blocks.0.attentions.0.norm.bias', 'down_blocks.0.attentions.0.proj_in.weight', 'down_blocks.0.attentions.0.proj_in.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.0.attentions.0.proj_out.weight', 'down_blocks.0.attentions.0.proj_out.bias', 'down_blocks.0.attentions.1.norm.weight', 'down_blocks.0.attentions.1.norm.bias', 'down_blocks.0.attentions.1.proj_in.weight', 'down_blocks.0.attentions.1.proj_in.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.0.attentions.1.proj_out.weight', 'down_blocks.0.attentions.1.proj_out.bias', 'down_blocks.0.resnets.0.norm1.weight', 'down_blocks.0.resnets.0.norm1.bias', 'down_blocks.0.resnets.0.conv1.weight', 'down_blocks.0.resnets.0.conv1.bias', 'down_blocks.0.resnets.0.time_emb_proj.weight', 'down_blocks.0.resnets.0.time_emb_proj.bias', 'down_blocks.0.resnets.0.norm2.weight', 'down_blocks.0.resnets.0.norm2.bias', 'down_blocks.0.resnets.0.conv2.weight', 'down_blocks.0.resnets.0.conv2.bias', 'down_blocks.0.resnets.1.norm1.weight', 'down_blocks.0.resnets.1.norm1.bias', 'down_blocks.0.resnets.1.conv1.weight', 'down_blocks.0.resnets.1.conv1.bias', 'down_blocks.0.resnets.1.time_emb_proj.weight', 'down_blocks.0.resnets.1.time_emb_proj.bias', 'down_blocks.0.resnets.1.norm2.weight', 'down_blocks.0.resnets.1.norm2.bias', 'down_blocks.0.resnets.1.conv2.weight', 'down_blocks.0.resnets.1.conv2.bias', 'down_blocks.0.downsamplers.0.conv.weight', 'down_blocks.0.downsamplers.0.conv.bias', 'down_blocks.1.attentions.0.norm.weight', 'down_blocks.1.attentions.0.norm.bias', 'down_blocks.1.attentions.0.proj_in.weight', 'down_blocks.1.attentions.0.proj_in.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.1.attentions.0.proj_out.weight', 'down_blocks.1.attentions.0.proj_out.bias', 'down_blocks.1.attentions.1.norm.weight', 'down_blocks.1.attentions.1.norm.bias', 'down_blocks.1.attentions.1.proj_in.weight', 'down_blocks.1.attentions.1.proj_in.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.1.attentions.1.proj_out.weight', 'down_blocks.1.attentions.1.proj_out.bias', 'down_blocks.1.resnets.0.norm1.weight', 'down_blocks.1.resnets.0.norm1.bias', 'down_blocks.1.resnets.0.conv1.weight', 'down_blocks.1.resnets.0.conv1.bias', 'down_blocks.1.resnets.0.time_emb_proj.weight', 'down_blocks.1.resnets.0.time_emb_proj.bias', 'down_blocks.1.resnets.0.norm2.weight', 'down_blocks.1.resnets.0.norm2.bias', 'down_blocks.1.resnets.0.conv2.weight', 'down_blocks.1.resnets.0.conv2.bias', 'down_blocks.1.resnets.0.conv_shortcut.weight', 'down_blocks.1.resnets.0.conv_shortcut.bias', 'down_blocks.1.resnets.1.norm1.weight', 'down_blocks.1.resnets.1.norm1.bias', 'down_blocks.1.resnets.1.conv1.weight', 'down_blocks.1.resnets.1.conv1.bias', 'down_blocks.1.resnets.1.time_emb_proj.weight', 'down_blocks.1.resnets.1.time_emb_proj.bias', 'down_blocks.1.resnets.1.norm2.weight', 'down_blocks.1.resnets.1.norm2.bias', 'down_blocks.1.resnets.1.conv2.weight', 'down_blocks.1.resnets.1.conv2.bias', 'down_blocks.1.downsamplers.0.conv.weight', 'down_blocks.1.downsamplers.0.conv.bias', 'down_blocks.2.attentions.0.norm.weight', 'down_blocks.2.attentions.0.norm.bias', 'down_blocks.2.attentions.0.proj_in.weight', 'down_blocks.2.attentions.0.proj_in.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.2.attentions.0.proj_out.weight', 'down_blocks.2.attentions.0.proj_out.bias', 'down_blocks.2.attentions.1.norm.weight', 'down_blocks.2.attentions.1.norm.bias', 'down_blocks.2.attentions.1.proj_in.weight', 'down_blocks.2.attentions.1.proj_in.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.2.attentions.1.proj_out.weight', 'down_blocks.2.attentions.1.proj_out.bias', 'down_blocks.2.resnets.0.norm1.weight', 'down_blocks.2.resnets.0.norm1.bias', 'down_blocks.2.resnets.0.conv1.weight', 'down_blocks.2.resnets.0.conv1.bias', 'down_blocks.2.resnets.0.time_emb_proj.weight', 'down_blocks.2.resnets.0.time_emb_proj.bias', 'down_blocks.2.resnets.0.norm2.weight', 'down_blocks.2.resnets.0.norm2.bias', 'down_blocks.2.resnets.0.conv2.weight', 'down_blocks.2.resnets.0.conv2.bias', 'down_blocks.2.resnets.0.conv_shortcut.weight', 'down_blocks.2.resnets.0.conv_shortcut.bias', 'down_blocks.2.resnets.1.norm1.weight', 'down_blocks.2.resnets.1.norm1.bias', 'down_blocks.2.resnets.1.conv1.weight', 'down_blocks.2.resnets.1.conv1.bias', 'down_blocks.2.resnets.1.time_emb_proj.weight', 'down_blocks.2.resnets.1.time_emb_proj.bias', 'down_blocks.2.resnets.1.norm2.weight', 'down_blocks.2.resnets.1.norm2.bias', 'down_blocks.2.resnets.1.conv2.weight', 'down_blocks.2.resnets.1.conv2.bias', 'down_blocks.2.downsamplers.0.conv.weight', 'down_blocks.2.downsamplers.0.conv.bias', 'down_blocks.3.resnets.0.norm1.weight', 'down_blocks.3.resnets.0.norm1.bias', 'down_blocks.3.resnets.0.conv1.weight', 'down_blocks.3.resnets.0.conv1.bias', 'down_blocks.3.resnets.0.time_emb_proj.weight', 'down_blocks.3.resnets.0.time_emb_proj.bias', 'down_blocks.3.resnets.0.norm2.weight', 'down_blocks.3.resnets.0.norm2.bias', 'down_blocks.3.resnets.0.conv2.weight', 'down_blocks.3.resnets.0.conv2.bias', 'down_blocks.3.resnets.1.norm1.weight', 'down_blocks.3.resnets.1.norm1.bias', 'down_blocks.3.resnets.1.conv1.weight', 'down_blocks.3.resnets.1.conv1.bias', 'down_blocks.3.resnets.1.time_emb_proj.weight', 'down_blocks.3.resnets.1.time_emb_proj.bias', 'down_blocks.3.resnets.1.norm2.weight', 'down_blocks.3.resnets.1.norm2.bias', 'down_blocks.3.resnets.1.conv2.weight', 'down_blocks.3.resnets.1.conv2.bias', 'up_blocks.0.resnets.0.norm1.weight', 'up_blocks.0.resnets.0.norm1.bias', 'up_blocks.0.resnets.0.conv1.weight', 'up_blocks.0.resnets.0.conv1.bias', 'up_blocks.0.resnets.0.time_emb_proj.weight', 'up_blocks.0.resnets.0.time_emb_proj.bias', 'up_blocks.0.resnets.0.norm2.weight', 'up_blocks.0.resnets.0.norm2.bias', 'up_blocks.0.resnets.0.conv2.weight', 'up_blocks.0.resnets.0.conv2.bias', 'up_blocks.0.resnets.0.conv_shortcut.weight', 'up_blocks.0.resnets.0.conv_shortcut.bias', 'up_blocks.0.resnets.1.norm1.weight', 'up_blocks.0.resnets.1.norm1.bias', 'up_blocks.0.resnets.1.conv1.weight', 'up_blocks.0.resnets.1.conv1.bias', 'up_blocks.0.resnets.1.time_emb_proj.weight', 'up_blocks.0.resnets.1.time_emb_proj.bias', 'up_blocks.0.resnets.1.norm2.weight', 'up_blocks.0.resnets.1.norm2.bias', 'up_blocks.0.resnets.1.conv2.weight', 'up_blocks.0.resnets.1.conv2.bias', 'up_blocks.0.resnets.1.conv_shortcut.weight', 'up_blocks.0.resnets.1.conv_shortcut.bias', 'up_blocks.0.resnets.2.norm1.weight', 'up_blocks.0.resnets.2.norm1.bias', 'up_blocks.0.resnets.2.conv1.weight', 'up_blocks.0.resnets.2.conv1.bias', 'up_blocks.0.resnets.2.time_emb_proj.weight', 'up_blocks.0.resnets.2.time_emb_proj.bias', 'up_blocks.0.resnets.2.norm2.weight', 'up_blocks.0.resnets.2.norm2.bias', 'up_blocks.0.resnets.2.conv2.weight', 'up_blocks.0.resnets.2.conv2.bias', 'up_blocks.0.resnets.2.conv_shortcut.weight', 'up_blocks.0.resnets.2.conv_shortcut.bias', 'up_blocks.0.upsamplers.0.conv.weight', 'up_blocks.0.upsamplers.0.conv.bias', 'up_blocks.1.attentions.0.norm.weight', 'up_blocks.1.attentions.0.norm.bias', 'up_blocks.1.attentions.0.proj_in.weight', 'up_blocks.1.attentions.0.proj_in.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.0.proj_out.weight', 'up_blocks.1.attentions.0.proj_out.bias', 'up_blocks.1.attentions.1.norm.weight', 'up_blocks.1.attentions.1.norm.bias', 'up_blocks.1.attentions.1.proj_in.weight', 'up_blocks.1.attentions.1.proj_in.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.1.proj_out.weight', 'up_blocks.1.attentions.1.proj_out.bias', 'up_blocks.1.attentions.2.norm.weight', 'up_blocks.1.attentions.2.norm.bias', 'up_blocks.1.attentions.2.proj_in.weight', 'up_blocks.1.attentions.2.proj_in.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.2.proj_out.weight', 'up_blocks.1.attentions.2.proj_out.bias', 'up_blocks.1.resnets.0.norm1.weight', 'up_blocks.1.resnets.0.norm1.bias', 'up_blocks.1.resnets.0.conv1.weight', 'up_blocks.1.resnets.0.conv1.bias', 'up_blocks.1.resnets.0.time_emb_proj.weight', 'up_blocks.1.resnets.0.time_emb_proj.bias', 'up_blocks.1.resnets.0.norm2.weight', 'up_blocks.1.resnets.0.norm2.bias', 'up_blocks.1.resnets.0.conv2.weight', 'up_blocks.1.resnets.0.conv2.bias', 'up_blocks.1.resnets.0.conv_shortcut.weight', 'up_blocks.1.resnets.0.conv_shortcut.bias', 'up_blocks.1.resnets.1.norm1.weight', 'up_blocks.1.resnets.1.norm1.bias', 'up_blocks.1.resnets.1.conv1.weight', 'up_blocks.1.resnets.1.conv1.bias', 'up_blocks.1.resnets.1.time_emb_proj.weight', 'up_blocks.1.resnets.1.time_emb_proj.bias', 'up_blocks.1.resnets.1.norm2.weight', 'up_blocks.1.resnets.1.norm2.bias', 'up_blocks.1.resnets.1.conv2.weight', 'up_blocks.1.resnets.1.conv2.bias', 'up_blocks.1.resnets.1.conv_shortcut.weight', 'up_blocks.1.resnets.1.conv_shortcut.bias', 'up_blocks.1.resnets.2.norm1.weight', 'up_blocks.1.resnets.2.norm1.bias', 'up_blocks.1.resnets.2.conv1.weight', 'up_blocks.1.resnets.2.conv1.bias', 'up_blocks.1.resnets.2.time_emb_proj.weight', 'up_blocks.1.resnets.2.time_emb_proj.bias', 'up_blocks.1.resnets.2.norm2.weight', 'up_blocks.1.resnets.2.norm2.bias', 'up_blocks.1.resnets.2.conv2.weight', 'up_blocks.1.resnets.2.conv2.bias', 'up_blocks.1.resnets.2.conv_shortcut.weight', 'up_blocks.1.resnets.2.conv_shortcut.bias', 'up_blocks.1.upsamplers.0.conv.weight', 'up_blocks.1.upsamplers.0.conv.bias', 'up_blocks.2.attentions.0.norm.weight', 'up_blocks.2.attentions.0.norm.bias', 'up_blocks.2.attentions.0.proj_in.weight', 'up_blocks.2.attentions.0.proj_in.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.0.proj_out.weight', 'up_blocks.2.attentions.0.proj_out.bias', 'up_blocks.2.attentions.1.norm.weight', 'up_blocks.2.attentions.1.norm.bias', 'up_blocks.2.attentions.1.proj_in.weight', 'up_blocks.2.attentions.1.proj_in.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.1.proj_out.weight', 'up_blocks.2.attentions.1.proj_out.bias', 'up_blocks.2.attentions.2.norm.weight', 'up_blocks.2.attentions.2.norm.bias', 'up_blocks.2.attentions.2.proj_in.weight', 'up_blocks.2.attentions.2.proj_in.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.2.proj_out.weight', 'up_blocks.2.attentions.2.proj_out.bias', 'up_blocks.2.resnets.0.norm1.weight', 'up_blocks.2.resnets.0.norm1.bias', 'up_blocks.2.resnets.0.conv1.weight', 'up_blocks.2.resnets.0.conv1.bias', 'up_blocks.2.resnets.0.time_emb_proj.weight', 'up_blocks.2.resnets.0.time_emb_proj.bias', 'up_blocks.2.resnets.0.norm2.weight', 'up_blocks.2.resnets.0.norm2.bias', 'up_blocks.2.resnets.0.conv2.weight', 'up_blocks.2.resnets.0.conv2.bias', 'up_blocks.2.resnets.0.conv_shortcut.weight', 'up_blocks.2.resnets.0.conv_shortcut.bias', 'up_blocks.2.resnets.1.norm1.weight', 'up_blocks.2.resnets.1.norm1.bias', 'up_blocks.2.resnets.1.conv1.weight', 'up_blocks.2.resnets.1.conv1.bias', 'up_blocks.2.resnets.1.time_emb_proj.weight', 'up_blocks.2.resnets.1.time_emb_proj.bias', 'up_blocks.2.resnets.1.norm2.weight', 'up_blocks.2.resnets.1.norm2.bias', 'up_blocks.2.resnets.1.conv2.weight', 'up_blocks.2.resnets.1.conv2.bias', 'up_blocks.2.resnets.1.conv_shortcut.weight', 'up_blocks.2.resnets.1.conv_shortcut.bias', 'up_blocks.2.resnets.2.norm1.weight', 'up_blocks.2.resnets.2.norm1.bias', 'up_blocks.2.resnets.2.conv1.weight', 'up_blocks.2.resnets.2.conv1.bias', 'up_blocks.2.resnets.2.time_emb_proj.weight', 'up_blocks.2.resnets.2.time_emb_proj.bias', 'up_blocks.2.resnets.2.norm2.weight', 'up_blocks.2.resnets.2.norm2.bias', 'up_blocks.2.resnets.2.conv2.weight', 'up_blocks.2.resnets.2.conv2.bias', 'up_blocks.2.resnets.2.conv_shortcut.weight', 'up_blocks.2.resnets.2.conv_shortcut.bias', 'up_blocks.2.upsamplers.0.conv.weight', 'up_blocks.2.upsamplers.0.conv.bias', 'up_blocks.3.attentions.0.norm.weight', 'up_blocks.3.attentions.0.norm.bias', 'up_blocks.3.attentions.0.proj_in.weight', 'up_blocks.3.attentions.0.proj_in.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.0.proj_out.weight', 'up_blocks.3.attentions.0.proj_out.bias', 'up_blocks.3.attentions.1.norm.weight', 'up_blocks.3.attentions.1.norm.bias', 'up_blocks.3.attentions.1.proj_in.weight', 'up_blocks.3.attentions.1.proj_in.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.1.proj_out.weight', 'up_blocks.3.attentions.1.proj_out.bias', 'up_blocks.3.attentions.2.norm.weight', 'up_blocks.3.attentions.2.norm.bias', 'up_blocks.3.attentions.2.proj_in.weight', 'up_blocks.3.attentions.2.proj_in.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.2.proj_out.weight', 'up_blocks.3.attentions.2.proj_out.bias', 'up_blocks.3.resnets.0.norm1.weight', 'up_blocks.3.resnets.0.norm1.bias', 'up_blocks.3.resnets.0.conv1.weight', 'up_blocks.3.resnets.0.conv1.bias', 'up_blocks.3.resnets.0.time_emb_proj.weight', 'up_blocks.3.resnets.0.time_emb_proj.bias', 'up_blocks.3.resnets.0.norm2.weight', 'up_blocks.3.resnets.0.norm2.bias', 'up_blocks.3.resnets.0.conv2.weight', 'up_blocks.3.resnets.0.conv2.bias', 'up_blocks.3.resnets.0.conv_shortcut.weight', 'up_blocks.3.resnets.0.conv_shortcut.bias', 'up_blocks.3.resnets.1.norm1.weight', 'up_blocks.3.resnets.1.norm1.bias', 'up_blocks.3.resnets.1.conv1.weight', 'up_blocks.3.resnets.1.conv1.bias', 'up_blocks.3.resnets.1.time_emb_proj.weight', 'up_blocks.3.resnets.1.time_emb_proj.bias', 'up_blocks.3.resnets.1.norm2.weight', 'up_blocks.3.resnets.1.norm2.bias', 'up_blocks.3.resnets.1.conv2.weight', 'up_blocks.3.resnets.1.conv2.bias', 'up_blocks.3.resnets.1.conv_shortcut.weight', 'up_blocks.3.resnets.1.conv_shortcut.bias', 'up_blocks.3.resnets.2.norm1.weight', 'up_blocks.3.resnets.2.norm1.bias', 'up_blocks.3.resnets.2.conv1.weight', 'up_blocks.3.resnets.2.conv1.bias', 'up_blocks.3.resnets.2.time_emb_proj.weight', 'up_blocks.3.resnets.2.time_emb_proj.bias', 'up_blocks.3.resnets.2.norm2.weight', 'up_blocks.3.resnets.2.norm2.bias', 'up_blocks.3.resnets.2.conv2.weight', 'up_blocks.3.resnets.2.conv2.bias', 'up_blocks.3.resnets.2.conv_shortcut.weight', 'up_blocks.3.resnets.2.conv_shortcut.bias', 'mid_block.attentions.0.norm.weight', 'mid_block.attentions.0.norm.bias', 'mid_block.attentions.0.proj_in.weight', 'mid_block.attentions.0.proj_in.bias', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'mid_block.attentions.0.transformer_blocks.0.norm1.weight', 'mid_block.attentions.0.transformer_blocks.0.norm1.bias', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'mid_block.attentions.0.transformer_blocks.0.norm2.weight', 'mid_block.attentions.0.transformer_blocks.0.norm2.bias', 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight', 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias', 'mid_block.attentions.0.transformer_blocks.0.norm3.weight', 'mid_block.attentions.0.transformer_blocks.0.norm3.bias', 'mid_block.attentions.0.proj_out.weight', 'mid_block.attentions.0.proj_out.bias', 'mid_block.resnets.0.norm1.weight', 'mid_block.resnets.0.norm1.bias', 'mid_block.resnets.0.conv1.weight', 'mid_block.resnets.0.conv1.bias', 'mid_block.resnets.0.time_emb_proj.weight', 'mid_block.resnets.0.time_emb_proj.bias', 'mid_block.resnets.0.norm2.weight', 'mid_block.resnets.0.norm2.bias', 'mid_block.resnets.0.conv2.weight', 'mid_block.resnets.0.conv2.bias', 'mid_block.resnets.1.norm1.weight', 'mid_block.resnets.1.norm1.bias', 'mid_block.resnets.1.conv1.weight', 'mid_block.resnets.1.conv1.bias', 'mid_block.resnets.1.time_emb_proj.weight', 'mid_block.resnets.1.time_emb_proj.bias', 'mid_block.resnets.1.norm2.weight', 'mid_block.resnets.1.norm2.bias', 'mid_block.resnets.1.conv2.weight', 'mid_block.resnets.1.conv2.bias', 'conv_norm_out.weight', 'conv_norm_out.bias', 'conv_out.weight', 'conv_out.bias'], unexpected keys: []
### trainable params number: 546
### trainable params scale: 453.209 M
### loading annotations from data/animated_diff_ds_1704397657.csv ...
### data scale: 119
