training config: {'image_finetune': False, 'output_dir': 'output_1704418358', 'pretrained_model_path': 'models/StableDiffusion', 'unet_additional_kwargs': {'use_inflated_groupnorm': True, 'unet_use_cross_frame_attention': False, 'unet_use_temporal_attention': False, 'use_motion_module': True, 'motion_module_resolutions': [1, 2, 4, 8], 'motion_module_mid_block': True, 'motion_module_decoder_only': False, 'motion_module_type': 'Vanilla', 'motion_module_kwargs': {'num_attention_heads': 8, 'num_transformer_block': 1, 'attention_block_types': ['Temporal_Self', 'Temporal_Self'], 'temporal_position_encoding': True, 'temporal_position_encoding_max_len': 32, 'temporal_attention_dim_div': 1}}, 'noise_scheduler_kwargs': {'num_train_timesteps': 1000, 'beta_start': 0.00085, 'beta_end': 0.012, 'beta_schedule': 'linear', 'steps_offset': 1, 'clip_sample': False}, 'train_data': {'csv_path': 'data/animated_diff_ds_1704397657.csv', 'video_folder': 'data/', 'sample_size': 256, 'sample_stride': 4, 'sample_n_frames': 16}, 'validation_data': {'prompts': ['A sprite sheet animation of green color bullet effect from bottom of the screen to the top.', 'A sprite sheet animation of a fire with smokes around it.'], 'num_inference_steps': 25, 'guidance_scale': 8.0}, 'trainable_modules': ['motion_modules.'], 'unet_checkpoint_path': 'models/Motion_Module/mm_sd_v15_v2.ckpt', 'dreambooth_path': 'models/DreamBooth_LoRA/realisticVisionV60B1_v51VAE.safetensors', 'learning_rate': 0.0001, 'train_batch_size': 4, 'max_train_epoch': -1, 'max_train_steps': 10000, 'checkpointing_epochs': -1, 'checkpointing_steps': 5000, 'validation_steps': 100, 'validation_steps_tuple': [2, 50], 'global_seed': 42, 'mixed_precision_training': True, 'enable_xformers_memory_efficient_attention': True, 'is_debug': False}
using output_dir: output_1704418358/sprite_sheet_training-2024-01-05T01-32-48
using max tokens: 77
loaded 3D unet's pretrained weights from models/StableDiffusion/unet ...
### missing keys: 588; 
### unexpected keys: 0;
### Motion Module Parameters: 453.20928 M
unet_checkpoint_path: models/Motion_Module/mm_sd_v15_v2.ckpt
### from checkpoint: models/Motion_Module/mm_sd_v15_v2.ckpt
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: down_blocks.0.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: down_blocks.1.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.2.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: down_blocks.3.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.0.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: up_blocks.1.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([1280])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([5120, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([5120])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([640, 2560])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([640, 640])
state_dict key: up_blocks.2.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([640])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.1.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_in.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_in.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([2560, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([2560])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([320, 1280])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_out.weight, value:torch.Size([320, 320])
state_dict key: up_blocks.3.motion_modules.2.temporal_transformer.proj_out.bias, value:torch.Size([320])
state_dict key: mid_block.motion_modules.0.temporal_transformer.norm.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.norm.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_in.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_in.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.to_out.0.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.0.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_q.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_k.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_v.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.to_out.0.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.attention_blocks.1.pos_encoder.pe, value:torch.Size([1, 32, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.0.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.norms.1.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.weight, value:torch.Size([10240, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.0.proj.bias, value:torch.Size([10240])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.weight, value:torch.Size([1280, 5120])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff.net.2.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.weight, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.transformer_blocks.0.ff_norm.bias, value:torch.Size([1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_out.weight, value:torch.Size([1280, 1280])
state_dict key: mid_block.motion_modules.0.temporal_transformer.proj_out.bias, value:torch.Size([1280])
### missing keys: 686, unexpected keys: 0, total keys: 588
dreambooth_path: models/DreamBooth_LoRA/realisticVisionV60B1_v51VAE.safetensors
load dreambooth model from models/DreamBooth_LoRA/realisticVisionV60B1_v51VAE.safetensors
### missing keys: 0, unexpected keys: 0, total keys: 248
### missing keys: 588, unexpected keys: 0, total keys: 686
### newly loaded text_encoder: CLIPTextModel(
  (text_model): CLIPTextTransformer(
    (embeddings): CLIPTextEmbeddings(
      (token_embedding): Embedding(49408, 768)
      (position_embedding): Embedding(77, 768)
    )
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0-11): 12 x CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (activation_fn): QuickGELUActivation()
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
### trainable params number: 546
### trainable params scale: 453.209 M
### loading annotations from data/animated_diff_ds_1704397657.csv ...
### data scale: 117
