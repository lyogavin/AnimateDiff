{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f788bf-0b32-43f2-8118-74ef5f50c448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (0.7.0)\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.33.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decord in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (from imageio) (9.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (from imageio) (1.24.3)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.33.1\n"
     ]
    }
   ],
   "source": [
    "!pip install einops imageio decord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed3b706-d035-4a6f-8926-bf68701b8d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio[ffmpeg] in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (2.33.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (from imageio[ffmpeg]) (9.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (from imageio[ffmpeg]) (1.24.3)\n",
      "Collecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.4.9-py3-none-macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (22.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (from imageio[ffmpeg]) (5.9.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda3/envs/ghostaienv/lib/python3.8/site-packages (from imageio-ffmpeg->imageio[ffmpeg]) (63.4.1)\n",
      "Installing collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.4.9\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50f4ddf-1ba3-41a2-9f8f-5236b720e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/l_y_o/Work/AnimateDiff/data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8395b5c7-e238-4610-afc7-39563f08b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/l_y_o/Work/AnimateDiff\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a963a01a-b4e0-4177-a0b9-3d99dbc2a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, csv, math, random\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from decord import VideoReader\n",
    "\n",
    "\n",
    "from animatediff.data.gif_reader import GifReader\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "def zero_rank_print(*args):\n",
    "    print(*args)\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "# import RandomIoUCrop\n",
    "# transforms = RandomIoUCrop()\n",
    "\n",
    "def tranform_image(img):\n",
    "    try:\n",
    "        w, h = img.shape[-2:]\n",
    "        if w == h:\n",
    "            pass\n",
    "        elif w > h:\n",
    "            transform = v2.Pad((0, int((w - h) / 2), 0, int((w - h) / 2)), padding_mode='edge')\n",
    "            img = transform(img)\n",
    "        else:\n",
    "            transform = v2.Pad((int((h - w) / 2), 0, int((h - w) / 2), 0), padding_mode='edge')\n",
    "            img = transform(img)\n",
    "        \n",
    "    \n",
    "        return img\n",
    "    except Exception as ex:\n",
    "        print(f\"eror: {ex}, img:{img.shape}\")\n",
    "        raise ex\n",
    "\n",
    "\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        return tranform_image(image)\n",
    "\n",
    "\n",
    "\n",
    "class WebVid10M(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            csv_path, video_folder,\n",
    "            sample_size=256, sample_stride=4, sample_n_frames=16,\n",
    "            is_image=False,\n",
    "        ):\n",
    "        zero_rank_print(f\"loading annotations from {csv_path} ...\")\n",
    "        with open(csv_path, 'r') as csvfile:\n",
    "            self.dataset = list(csv.DictReader(csvfile))\n",
    "        self.length = len(self.dataset)\n",
    "        zero_rank_print(f\"data scale: {self.length}\")\n",
    "\n",
    "        self.video_folder    = video_folder\n",
    "        self.sample_stride   = sample_stride\n",
    "        self.sample_n_frames = sample_n_frames\n",
    "        self.is_image        = is_image\n",
    "        \n",
    "        sample_size = tuple(sample_size) if not isinstance(sample_size, int) else (sample_size, sample_size)\n",
    "        self.pixel_transforms = transforms.Compose([\n",
    "            SquarePad(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize(sample_size[0], antialias=True),\n",
    "            transforms.CenterCrop(sample_size),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], inplace=True),\n",
    "        ])\n",
    "    \n",
    "    def get_batch(self, idx):\n",
    "        video_dict = self.dataset[idx]\n",
    "        videoid, name, page_dir = video_dict['videoid'], video_dict['name'], video_dict['page_dir']\n",
    "\n",
    "        file_ext = 'mp4'\n",
    "        if 'file_ext' in video_dict:\n",
    "            file_ext = video_dict['file_ext']\n",
    "\n",
    "        if file_ext == 'mp4':\n",
    "            video_dir    = os.path.join(self.video_folder,  f\"{videoid}.mp4\")\n",
    "            video_reader = VideoReader(video_dir)\n",
    "        else:\n",
    "            video_dir    = os.path.join(self.video_folder, page_dir, f\"{videoid}.{file_ext}\")\n",
    "            video_reader = GifReader(video_dir)\n",
    "        video_length = len(video_reader)\n",
    "        \n",
    "        if not self.is_image:\n",
    "            clip_length = min(video_length, (self.sample_n_frames - 1) * self.sample_stride + 1)\n",
    "            start_idx   = random.randint(0, video_length - clip_length)\n",
    "            batch_index = np.linspace(start_idx, start_idx + clip_length - 1, self.sample_n_frames, dtype=int)\n",
    "        else:\n",
    "            batch_index = [random.randint(0, video_length - 1)]\n",
    "\n",
    "        if file_ext == 'mp4':\n",
    "            pixel_values = torch.from_numpy(video_reader.get_batch(batch_index).asnumpy()).permute(0, 3, 1, 2).contiguous()\n",
    "        else:\n",
    "            pixel_values = torch.from_numpy(video_reader.get_batch(batch_index)).permute(0, 3, 1, 2).contiguous()\n",
    "        pixel_values = pixel_values / 255.\n",
    "        del video_reader\n",
    "\n",
    "        if self.is_image:\n",
    "            pixel_values = pixel_values[0]\n",
    "        \n",
    "        return pixel_values, name, page_dir, videoid\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            try:\n",
    "                pixel_values, name, page_dir, videoid = self.get_batch(idx)\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"error loading {idx}: {e}\")\n",
    "                idx = random.randint(0, self.length-1)\n",
    "\n",
    "        pixel_values = self.pixel_transforms(pixel_values)\n",
    "        sample = dict(pixel_values=pixel_values, text=name , page_dir=page_dir, videoid=videoid)\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5d5d1b-72fe-4f85-ae2b-625d8add136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "import torchvision\n",
    "def save_videos_grid(videos: torch.Tensor, path: str, rescale=False, n_rows=6, fps=8):\n",
    "    videos = rearrange(videos, \"b c t h w -> t b c h w\")\n",
    "    outputs = []\n",
    "    for x in videos:\n",
    "        x = torchvision.utils.make_grid(x, nrow=n_rows)\n",
    "        x = x.transpose(0, 1).transpose(1, 2).squeeze(-1)\n",
    "        if rescale:\n",
    "            x = (x + 1.0) / 2.0  # -1,1 -> 0,1\n",
    "        x = (x * 255).numpy().astype(np.uint8)\n",
    "        outputs.append(x)\n",
    "\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    imageio.mimsave(path, outputs, fps=fps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b524b5a-3414-4c0e-ad5e-3931491d89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations from ./data/animated_diff_ds_1704397657.csv ...\n",
      "data scale: 117\n",
      "torch.Size([4, 16, 3, 256, 256]) 4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['JV24kJi', '3fe3291bf506e4c66dddd3b6f51b7656_w200', 'olga-ryzhychenko-31', 'EEPpNs']: as 0-0.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['JV24kJi', '3fe3291bf506e4c66dddd3b6f51b7656_w200', 'olga-ryzhychenko-31', 'EEPpNs']: as 0-1.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['JV24kJi', '3fe3291bf506e4c66dddd3b6f51b7656_w200', 'olga-ryzhychenko-31', 'EEPpNs']: as 0-2.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['JV24kJi', '3fe3291bf506e4c66dddd3b6f51b7656_w200', 'olga-ryzhychenko-31', 'EEPpNs']: as 0-3.mp4\n",
      "torch.Size([4, 16, 3, 256, 256]) 4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['giphy', 'jeong-h-lee-ezgif-com-resize', 'ezgif.com-video-to-gif+(14)', '761391_6bc8c']: as 1-0.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['giphy', 'jeong-h-lee-ezgif-com-resize', 'ezgif.com-video-to-gif+(14)', '761391_6bc8c']: as 1-1.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['giphy', 'jeong-h-lee-ezgif-com-resize', 'ezgif.com-video-to-gif+(14)', '761391_6bc8c']: as 1-2.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['giphy', 'jeong-h-lee-ezgif-com-resize', 'ezgif.com-video-to-gif+(14)', '761391_6bc8c']: as 1-3.mp4\n",
      "torch.Size([4, 16, 3, 256, 256]) 4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['ea9ff4824adba932f227084b09d0ec1e', '3MfZ', '2296431_9c6f7', 'image_processing20210614-9899-1rfm6to']: as 2-0.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['ea9ff4824adba932f227084b09d0ec1e', '3MfZ', '2296431_9c6f7', 'image_processing20210614-9899-1rfm6to']: as 2-1.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['ea9ff4824adba932f227084b09d0ec1e', '3MfZ', '2296431_9c6f7', 'image_processing20210614-9899-1rfm6to']: as 2-2.mp4\n",
      "['smoke', 'smoke', 'smoke', 'smoke']/['ea9ff4824adba932f227084b09d0ec1e', '3MfZ', '2296431_9c6f7', 'image_processing20210614-9899-1rfm6to']: as 2-3.mp4\n",
      "torch.Size([4, 16, 3, 256, 256]) 4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Lazer', 'source', '1223f768fd2005bb421094e80c6b1da1', 'SpaceWarp-Interactive-Art-IKONIX-low']: as 3-0.mp4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Lazer', 'source', '1223f768fd2005bb421094e80c6b1da1', 'SpaceWarp-Interactive-Art-IKONIX-low']: as 3-1.mp4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Lazer', 'source', '1223f768fd2005bb421094e80c6b1da1', 'SpaceWarp-Interactive-Art-IKONIX-low']: as 3-2.mp4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Lazer', 'source', '1223f768fd2005bb421094e80c6b1da1', 'SpaceWarp-Interactive-Art-IKONIX-low']: as 3-3.mp4\n",
      "torch.Size([4, 16, 3, 256, 256]) 4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Purple_Beam_buff', 'dcrjrui-5baabde8-4494-4ae5-8427-c3e5588598a7', '530934b3ec4ba0a8533d319147ed3301', '600244a253e0f707519756077a534933']: as 4-0.mp4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Purple_Beam_buff', 'dcrjrui-5baabde8-4494-4ae5-8427-c3e5588598a7', '530934b3ec4ba0a8533d319147ed3301', '600244a253e0f707519756077a534933']: as 4-1.mp4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Purple_Beam_buff', 'dcrjrui-5baabde8-4494-4ae5-8427-c3e5588598a7', '530934b3ec4ba0a8533d319147ed3301', '600244a253e0f707519756077a534933']: as 4-2.mp4\n",
      "['lazer beam', 'lazer beam', 'lazer beam', 'lazer beam']/['Purple_Beam_buff', 'dcrjrui-5baabde8-4494-4ae5-8427-c3e5588598a7', '530934b3ec4ba0a8533d319147ed3301', '600244a253e0f707519756077a534933']: as 4-3.mp4\n"
     ]
    }
   ],
   "source": [
    "#from animatediff.utils.util import save_videos_grid\n",
    "\n",
    "dataset = WebVid10M(\n",
    "    csv_path=\"./data/animated_diff_ds_1704397657.csv\",\n",
    "    video_folder=\"./data/\",\n",
    "    sample_size=256,\n",
    "    sample_stride=4, sample_n_frames=16,\n",
    "    is_image=False,\n",
    ")\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, num_workers=0,)\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    print(batch[\"pixel_values\"].shape, len(batch[\"text\"]))\n",
    "    for i in range(batch[\"pixel_values\"].shape[0]):\n",
    "        title = batch[\"text\"]\n",
    "        dir = batch['page_dir']\n",
    "        fn = batch['videoid']\n",
    "        save_videos_grid(batch[\"pixel_values\"][i:i+1].permute(0,2,1,3,4), os.path.join(\".\", f\"{idx}-{i}.mp4\"), rescale=True)\n",
    "        print(f\"{dir}/{fn}: as {idx}-{i}.mp4\")\n",
    "\n",
    "    if idx > 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b7ac8-49a2-48ef-8175-5c2248c46810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34fef99-3263-4910-9dd3-c173a4bb5388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c917260-ca9a-475e-83c7-e7c9c90f9777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
